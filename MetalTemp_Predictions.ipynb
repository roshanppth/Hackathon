{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "M5FAe-5CYWin"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn import metrics\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "buZv1L5EZEQ_"
   },
   "outputs": [],
   "source": [
    "Big_data_imputed = pd.read_csv('BigData_imputed.csv')\n",
    "Fur_merged = pd.read_csv('furnace_cylce_merged.csv')\n",
    "Fur_merged_final = pd.read_csv('furnace_cylce_merged_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "uGZCt3vBjNLX"
   },
   "outputs": [],
   "source": [
    "Fur_merged=Fur_merged.dropna()\n",
    "Fur_merged_final=Fur_merged_final.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_impute_list= list(Big_data_imputed[Big_data_imputed['Impute']==0].index)\n",
    "test_index= random.sample(non_impute_list, int(Big_data_imputed.shape[0]*.2))\n",
    "test_df  = Big_data_imputed[Big_data_imputed.index.isin(test_index)]\n",
    "train_df  = Big_data_imputed[~Big_data_imputed.index.isin(test_index)]\n",
    "x1_train = train_df['Current_Roof_Temp']\n",
    "x1_test = test_df['Current_Roof_Temp']\n",
    "y1_train = train_df['Metal_Temp']\n",
    "y1_test = test_df['Metal_Temp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "U3fE_soDZ4wT"
   },
   "outputs": [],
   "source": [
    "#split data into training and test data.\n",
    "# x1 = Big_data_imputed[['Current_Roof_Temp']].values\n",
    "# y1 = Big_data_imputed[['Metal_Temp']].values\n",
    "#split data into training and test data.\n",
    "x2 = Fur_merged[['Mins', 'Current_Roof_Temp']]\n",
    "y2 = Fur_merged[['Metal_Temp']]\n",
    "#split data into training and test data.\n",
    "x3 = Fur_merged_final[['Mins', 'Current_Roof_Temp', 'roof_temperature_1','roof_temperature_2']]\n",
    "y3 = Fur_merged_final[['Metal_Temp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "GLEKiXR5apsf"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# x1_train, x1_test, y1_train, y1_test = train_test_split(x1,y1, test_size = 0.3, random_state = 65)\n",
    "x2_train, x2_test, y2_train, y2_test = train_test_split(x2,y2, test_size = 0.3, random_state = 66)\n",
    "x3_train, x3_test, y3_train, y3_test = train_test_split(x3,y3, test_size = 0.3, random_state = 67)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FNJRTkHFb6DC"
   },
   "source": [
    "ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jCCEaz9Abvz1",
    "outputId": "23d5b323-00a0-4660-f3e5-94b84797eb52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "8667/8667 [==============================] - 5s 545us/step - loss: 382652.0312\n",
      "Epoch 2/25\n",
      "8667/8667 [==============================] - 5s 541us/step - loss: 203441.7031\n",
      "Epoch 3/25\n",
      "8667/8667 [==============================] - 5s 542us/step - loss: 87097.8516\n",
      "Epoch 4/25\n",
      "8667/8667 [==============================] - 5s 560us/step - loss: 30337.7422\n",
      "Epoch 5/25\n",
      "8667/8667 [==============================] - 5s 593us/step - loss: 19131.2305\n",
      "Epoch 6/25\n",
      "8667/8667 [==============================] - 5s 548us/step - loss: 19005.2754\n",
      "Epoch 7/25\n",
      "8667/8667 [==============================] - 5s 549us/step - loss: 19000.7480\n",
      "Epoch 8/25\n",
      "8667/8667 [==============================] - 5s 544us/step - loss: 18999.0645\n",
      "Epoch 9/25\n",
      "8667/8667 [==============================] - 5s 563us/step - loss: 18995.9238\n",
      "Epoch 10/25\n",
      "8667/8667 [==============================] - 5s 557us/step - loss: 18996.3359\n",
      "Epoch 11/25\n",
      "8667/8667 [==============================] - 5s 550us/step - loss: 18998.7148\n",
      "Epoch 12/25\n",
      "8667/8667 [==============================] - 5s 562us/step - loss: 18995.2227\n",
      "Epoch 13/25\n",
      "8667/8667 [==============================] - 5s 580us/step - loss: 18995.7090\n",
      "Epoch 14/25\n",
      "8667/8667 [==============================] - 5s 568us/step - loss: 19001.5391\n",
      "Epoch 15/25\n",
      "8667/8667 [==============================] - 5s 578us/step - loss: 18992.3164\n",
      "Epoch 16/25\n",
      "8667/8667 [==============================] - 5s 595us/step - loss: 18996.5605\n",
      "Epoch 17/25\n",
      "8667/8667 [==============================] - 5s 578us/step - loss: 18997.6172\n",
      "Epoch 18/25\n",
      "8667/8667 [==============================] - 5s 555us/step - loss: 18994.0449\n",
      "Epoch 19/25\n",
      "8667/8667 [==============================] - 5s 540us/step - loss: 18996.6758\n",
      "Epoch 20/25\n",
      "8667/8667 [==============================] - 5s 539us/step - loss: 18995.1035\n",
      "Epoch 21/25\n",
      "8667/8667 [==============================] - 5s 539us/step - loss: 18997.7422\n",
      "Epoch 22/25\n",
      "8667/8667 [==============================] - 5s 548us/step - loss: 18992.4355\n",
      "Epoch 23/25\n",
      "8667/8667 [==============================] - 5s 539us/step - loss: 18994.5156\n",
      "Epoch 24/25\n",
      "8667/8667 [==============================] - 5s 544us/step - loss: 18992.5859\n",
      "Epoch 25/25\n",
      "8667/8667 [==============================] - 5s 540us/step - loss: 18992.6230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10741601a90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import deeplearning libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    " \n",
    "# create ANN model\n",
    "model_ann = Sequential()\n",
    " \n",
    "# Defining the Input layer and FIRST hidden layer, both are same!\n",
    "model_ann.add(Dense(units=20, input_dim=1, kernel_initializer='normal', activation='relu'))\n",
    " \n",
    "# Defining the Second layer of the model\n",
    "# after the first layer we don't have to specify input_dim as keras configure it automatically\n",
    "model_ann.add(Dense(units=20, kernel_initializer='normal', activation='tanh'))\n",
    " \n",
    "# The output neuron is a single fully connected node \n",
    "# Since we will be predicting a single number\n",
    "model_ann.add(Dense(1, kernel_initializer='normal'))\n",
    " \n",
    "# Compiling the model\n",
    "model_ann.compile(loss='mean_squared_error', optimizer='adam')\n",
    " \n",
    "# Fitting the ANN to the Training set\n",
    "model_ann.fit(x1_train, y1_train ,batch_size = 20, epochs = 25, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_pred_train_ann= model_ann.predict(y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.37424008238308\n",
      "-0.12087735610409611\n",
      "65.68312958548196\n"
     ]
    }
   ],
   "source": [
    "print(np.sqrt(metrics.mean_squared_error(y1_test, y1_pred_train_ann)))\n",
    "print(metrics.r2_score(y1_test, y1_pred_train_ann))\n",
    "print(metrics.mean_absolute_error(y1_test, y1_pred_train_ann))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rlD2fPQ5h0N4",
    "outputId": "b097ebf1-717b-4663-92de-cd0f565d74a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "54/54 [==============================] - 0s 571us/step - loss: 479674.5625\n",
      "Epoch 2/25\n",
      "54/54 [==============================] - 0s 597us/step - loss: 477998.4062\n",
      "Epoch 3/25\n",
      "54/54 [==============================] - 0s 592us/step - loss: 476464.2812\n",
      "Epoch 4/25\n",
      "54/54 [==============================] - 0s 588us/step - loss: 474947.1250\n",
      "Epoch 5/25\n",
      "54/54 [==============================] - 0s 587us/step - loss: 473436.0312\n",
      "Epoch 6/25\n",
      "54/54 [==============================] - 0s 576us/step - loss: 471935.6875\n",
      "Epoch 7/25\n",
      "54/54 [==============================] - 0s 574us/step - loss: 470437.0312\n",
      "Epoch 8/25\n",
      "54/54 [==============================] - 0s 601us/step - loss: 468945.1562\n",
      "Epoch 9/25\n",
      "54/54 [==============================] - 0s 568us/step - loss: 467459.3125\n",
      "Epoch 10/25\n",
      "54/54 [==============================] - 0s 599us/step - loss: 465975.7188\n",
      "Epoch 11/25\n",
      "54/54 [==============================] - 0s 581us/step - loss: 464495.8125\n",
      "Epoch 12/25\n",
      "54/54 [==============================] - 0s 594us/step - loss: 463022.2500\n",
      "Epoch 13/25\n",
      "54/54 [==============================] - 0s 569us/step - loss: 461548.6250\n",
      "Epoch 14/25\n",
      "54/54 [==============================] - 0s 601us/step - loss: 460076.1875\n",
      "Epoch 15/25\n",
      "54/54 [==============================] - 0s 572us/step - loss: 458613.5312\n",
      "Epoch 16/25\n",
      "54/54 [==============================] - 0s 580us/step - loss: 457148.2812\n",
      "Epoch 17/25\n",
      "54/54 [==============================] - 0s 485us/step - loss: 455690.0312\n",
      "Epoch 18/25\n",
      "54/54 [==============================] - 0s 593us/step - loss: 454233.5000\n",
      "Epoch 19/25\n",
      "54/54 [==============================] - 0s 599us/step - loss: 452779.1562\n",
      "Epoch 20/25\n",
      "54/54 [==============================] - 0s 546us/step - loss: 451329.8125\n",
      "Epoch 21/25\n",
      "54/54 [==============================] - 0s 614us/step - loss: 449886.8125\n",
      "Epoch 22/25\n",
      "54/54 [==============================] - 0s 615us/step - loss: 448447.7500\n",
      "Epoch 23/25\n",
      "54/54 [==============================] - 0s 575us/step - loss: 447015.4688\n",
      "Epoch 24/25\n",
      "54/54 [==============================] - 0s 585us/step - loss: 445580.5000\n",
      "Epoch 25/25\n",
      "54/54 [==============================] - 0s 578us/step - loss: 444149.0625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10742a3fa30>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import deeplearning libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    " \n",
    "# create ANN model\n",
    "model_ann1 = Sequential()\n",
    " \n",
    "# Defining the Input layer and FIRST hidden layer, both are same!\n",
    "model_ann1.add(Dense(units=20, input_dim=2, kernel_initializer='normal', activation='relu'))\n",
    " \n",
    "# Defining the Second layer of the model\n",
    "# after the first layer we don't have to specify input_dim as keras configure it automatically\n",
    "model_ann1.add(Dense(units=20, kernel_initializer='normal', activation='tanh'))\n",
    " \n",
    "# The output neuron is a single fully connected node \n",
    "# Since we will be predicting a single number\n",
    "model_ann1.add(Dense(1, kernel_initializer='normal'))\n",
    " \n",
    "# Compiling the model\n",
    "model_ann1.compile(loss='mean_squared_error', optimizer='adam')\n",
    " \n",
    "# Fitting the ANN to the Training set\n",
    "\n",
    "model_ann1.fit(x2_train, y2_train ,batch_size = 20, epochs = 25, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184.6073415971793\n",
      "-0.0260235832437683\n",
      "127.4588715200612\n"
     ]
    }
   ],
   "source": [
    "y2_pred_train_ann= model_ann.predict(y2_test)\n",
    "\n",
    "print(np.sqrt(metrics.mean_squared_error(y2_test, y2_pred_train_ann)))\n",
    "print(metrics.r2_score(y2_test, y2_pred_train_ann))\n",
    "print(metrics.mean_absolute_error(y2_test, y2_pred_train_ann))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jbfmJurrh0Sa",
    "outputId": "cf5d0be6-9c23-4d57-f54a-e2ee655ce76c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "52/52 [==============================] - 0s 576us/step - loss: 493934.7188\n",
      "Epoch 2/25\n",
      "52/52 [==============================] - 0s 566us/step - loss: 492303.7500\n",
      "Epoch 3/25\n",
      "52/52 [==============================] - 0s 586us/step - loss: 490815.4688\n",
      "Epoch 4/25\n",
      "52/52 [==============================] - 0s 598us/step - loss: 489330.8438\n",
      "Epoch 5/25\n",
      "52/52 [==============================] - 0s 593us/step - loss: 487849.2500\n",
      "Epoch 6/25\n",
      "52/52 [==============================] - 0s 594us/step - loss: 486373.8750\n",
      "Epoch 7/25\n",
      "52/52 [==============================] - 0s 612us/step - loss: 484901.2812\n",
      "Epoch 8/25\n",
      "52/52 [==============================] - 0s 580us/step - loss: 483435.5312\n",
      "Epoch 9/25\n",
      "52/52 [==============================] - 0s 579us/step - loss: 481970.3750\n",
      "Epoch 10/25\n",
      "52/52 [==============================] - 0s 576us/step - loss: 480511.0938\n",
      "Epoch 11/25\n",
      "52/52 [==============================] - 0s 615us/step - loss: 479054.2812\n",
      "Epoch 12/25\n",
      "52/52 [==============================] - 0s 585us/step - loss: 477600.0938\n",
      "Epoch 13/25\n",
      "52/52 [==============================] - 0s 575us/step - loss: 476149.8125\n",
      "Epoch 14/25\n",
      "52/52 [==============================] - 0s 624us/step - loss: 474702.0000\n",
      "Epoch 15/25\n",
      "52/52 [==============================] - 0s 631us/step - loss: 473257.5000\n",
      "Epoch 16/25\n",
      "52/52 [==============================] - 0s 634us/step - loss: 471818.3125\n",
      "Epoch 17/25\n",
      "52/52 [==============================] - 0s 613us/step - loss: 470381.4062\n",
      "Epoch 18/25\n",
      "52/52 [==============================] - 0s 592us/step - loss: 468946.5000\n",
      "Epoch 19/25\n",
      "52/52 [==============================] - 0s 582us/step - loss: 467517.6250\n",
      "Epoch 20/25\n",
      "52/52 [==============================] - 0s 606us/step - loss: 466091.0625\n",
      "Epoch 21/25\n",
      "52/52 [==============================] - 0s 578us/step - loss: 464665.4062\n",
      "Epoch 22/25\n",
      "52/52 [==============================] - 0s 583us/step - loss: 463245.5625\n",
      "Epoch 23/25\n",
      "52/52 [==============================] - 0s 599us/step - loss: 461827.3438\n",
      "Epoch 24/25\n",
      "52/52 [==============================] - 0s 601us/step - loss: 460414.0000\n",
      "Epoch 25/25\n",
      "52/52 [==============================] - 0s 629us/step - loss: 459003.5312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10742ac5e20>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import deeplearning libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    " \n",
    "# create ANN model\n",
    "model_ann2 = Sequential()\n",
    " \n",
    "# Defining the Input layer and FIRST hidden layer, both are same!\n",
    "model_ann2.add(Dense(units=20, input_dim=4, kernel_initializer='normal', activation='relu'))\n",
    " \n",
    "# Defining the Second layer of the model\n",
    "# after the first layer we don't have to specify input_dim as keras configure it automatically\n",
    "model_ann2.add(Dense(units=20, kernel_initializer='normal', activation='tanh'))\n",
    " \n",
    "# The output neuron is a single fully connected node \n",
    "# Since we will be predicting a single number\n",
    "model_ann2.add(Dense(1, kernel_initializer='normal'))\n",
    " \n",
    "# Compiling the model\n",
    "model_ann2.compile(loss='mean_squared_error', optimizer='adam')\n",
    " \n",
    "# Fitting the ANN to the Training set\n",
    "model_ann2.fit(x3_train, y3_train ,batch_size = 20, epochs = 25, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174.23727259802925\n",
      "-0.01096978650724445\n",
      "121.96822836393672\n"
     ]
    }
   ],
   "source": [
    "y3_pred_train_ann= model_ann.predict(y3_test)\n",
    "\n",
    "print(np.sqrt(metrics.mean_squared_error(y3_test, y3_pred_train_ann)))\n",
    "print(metrics.r2_score(y3_test, y3_pred_train_ann))\n",
    "print(metrics.mean_absolute_error(y3_test, y3_pred_train_ann))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8XUsjtccaFw"
   },
   "source": [
    "Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2b2mO5xAcZIJ",
    "outputId": "95a0a65e-3f9e-4fb4-fd36-bb8ecc1d204b"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = Big_data_imputed.drop(columns=['Metal_Temp', 'Unnamed: 0', 'DateTime', 'Impute'],axis=1)\n",
    "\n",
    "Y1 = Big_data_imputed.Metal_Temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train, x1_test, y1_train, y1_test = train_test_split(X1,Y1, test_size = 0.3, random_state = 66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2b2mO5xAcZIJ",
    "outputId": "95a0a65e-3f9e-4fb4-fd36-bb8ecc1d204b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sak3g\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(oob_score=True, random_state=100)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf = RandomForestRegressor(n_estimators=100, oob_score=True, random_state=100)\n",
    "model_rf.fit(x1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_pred_train_rf= model_rf.predict(x1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127.71339835875861\n",
      "0.10153087827184049\n",
      "68.8936325261619\n"
     ]
    }
   ],
   "source": [
    "print(np.sqrt(metrics.mean_squared_error(y1_test, y1_pred_train_rf)))\n",
    "print(metrics.r2_score(y1_test, y1_pred_train_rf))\n",
    "print(metrics.mean_absolute_error(y1_test, y1_pred_train_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = Fur_merged.drop(columns=['Metal_Temp', 'Cycle', 'DateTime', 'Door_Status'],axis=1)\n",
    "y2 = Fur_merged[['Metal_Temp']]\n",
    "#split data into training and test data.\n",
    "x3 = Fur_merged_final.drop(columns=['Metal_Temp'],axis=1)\n",
    "y3 = Fur_merged_final[['Metal_Temp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2_train, x2_test, y2_train, y2_test = train_test_split(x2,y2, test_size = 0.3, random_state = 66)\n",
    "x3_train, x3_test, y3_train, y3_test = train_test_split(x3,y3, test_size = 0.3, random_state = 66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2b2mO5xAcZIJ",
    "outputId": "95a0a65e-3f9e-4fb4-fd36-bb8ecc1d204b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sak3g\\AppData\\Local\\Temp/ipykernel_6788/188278722.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model_rf1.fit(x2_train, y2_train)\n",
      "C:\\Users\\sak3g\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\sak3g\\AppData\\Local\\Temp/ipykernel_6788/188278722.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model_rf2.fit(x3_train, y3_train)\n",
      "C:\\Users\\sak3g\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(oob_score=True, random_state=100)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf1 = RandomForestRegressor(n_estimators=100, oob_score=True, random_state=100)\n",
    "model_rf2 = RandomForestRegressor(n_estimators=100, oob_score=True, random_state=100)\n",
    "model_rf1.fit(x2_train, y2_train) \n",
    "model_rf2.fit(x3_train, y3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106.24218636425613\n",
      "0.6601765024623498\n",
      "40.31809628008753\n",
      "100.89601103428413\n",
      "0.6234399285437441\n",
      "42.33641723356009\n"
     ]
    }
   ],
   "source": [
    "y2_pred_train_rf= model_rf1.predict(x2_test)\n",
    "y3_pred_train_rf= model_rf2.predict(x3_test)\n",
    "print(np.sqrt(metrics.mean_squared_error(y2_test, y2_pred_train_rf)))\n",
    "print(metrics.r2_score(y2_test, y2_pred_train_rf))\n",
    "print(metrics.mean_absolute_error(y2_test, y2_pred_train_rf))\n",
    "\n",
    "print(np.sqrt(metrics.mean_squared_error(y3_test, y3_pred_train_rf)))\n",
    "print(metrics.r2_score(y3_test, y3_pred_train_rf))\n",
    "print(metrics.mean_absolute_error(y3_test, y3_pred_train_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mkg3RmNLknbB"
   },
   "source": [
    "SVM Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IiFYFLinktys",
    "outputId": "650b928e-4d44-4c55-8024-68d9e2588a26"
   },
   "outputs": [],
   "source": [
    "#SVM Regression\n",
    "from sklearn import svm\n",
    "RegModel = svm.SVR(C=2, kernel='linear')\n",
    "RegModel1 = svm.SVR(C=2, kernel='linear')\n",
    "RegModel2 = svm.SVR(C=2, kernel='linear')\n",
    "#Creating the model on Training Data\n",
    "RegModel.fit(x1_train,y1_train)\n",
    "RegModel1.fit(x2_train,y2_train)\n",
    "RegModel2.fit(x3_train,y3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_prediction1=RegModel.predict(x1_test)\n",
    "svm_prediction2=RegModel1.predict(x2_test)\n",
    "svm_prediction3=RegModel2.predict(x3_test)\n",
    "\n",
    "print(np.sqrt(metrics.mean_squared_error(y1_test,svm_prediction1)))\n",
    "print(metrics.r2_score(y1_test, svm_prediction1))\n",
    "print(metrics.mean_absolute_error(y1_test, svm_prediction1))\n",
    "\n",
    "print(np.sqrt(metrics.mean_squared_error(y2_test,svm_prediction2)))\n",
    "print(metrics.r2_score(y2_test, svm_prediction2))\n",
    "print(metrics.mean_absolute_error(y2_test, svm_prediction2))\n",
    "\n",
    "print(np.sqrt(metrics.mean_squared_error(y3_test,svm_prediction3)))\n",
    "print(metrics.r2_score(y3_test, svm_prediction3))\n",
    "print(metrics.mean_absolute_error(y3_test, svm_prediction3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UHSAZ5olmHza"
   },
   "source": [
    "Gaussian Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "UGMGlP3zmLu7"
   },
   "outputs": [],
   "source": [
    "#GP\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "UGMGlP3zmLu7"
   },
   "outputs": [],
   "source": [
    "kernel = 1 * RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e2))\n",
    "gaussian_process = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9)\n",
    "gaussian_process1 = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9)\n",
    "gaussian_process2 = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "UGMGlP3zmLu7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sak3g\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sak3g\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GaussianProcessRegressor(kernel=1**2 * RBF(length_scale=1),\n",
       "                         n_restarts_optimizer=9)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_process1.fit(x2_train, y2_train)\n",
    "gaussian_process2.fit(x3_train, y3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "UGMGlP3zmLu7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "316**2 * RBF(length_scale=12.6)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_process1.kernel_\n",
    "gaussian_process2.kernel_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_pred1= gaussian_process1.predict(x2_test)\n",
    "gaussian_pred2= gaussian_process2.predict(x3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687.0229389840345\n",
      "-13.2102553606347\n",
      "662.4085818996369\n",
      "292.0518844625172\n",
      "-2.155050393405612\n",
      "193.28962485498988\n"
     ]
    }
   ],
   "source": [
    "print(np.sqrt(metrics.mean_squared_error(y2_test,gaussian_pred1)))\n",
    "print(metrics.r2_score(y2_test, gaussian_pred1))\n",
    "print(metrics.mean_absolute_error(y2_test, gaussian_pred1))\n",
    "\n",
    "print(np.sqrt(metrics.mean_squared_error(y3_test,gaussian_pred2)))\n",
    "print(metrics.r2_score(y3_test, gaussian_pred2))\n",
    "print(metrics.mean_absolute_error(y3_test, gaussian_pred2))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Hack3.0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
