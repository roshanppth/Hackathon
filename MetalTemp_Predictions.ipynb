{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hack3.0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "M5FAe-5CYWin"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style('darkgrid')\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Big_data_imputed = pd.read_csv('BigData_imputed.csv')\n",
        "Fur_merged = pd.read_csv('furnace_cylce_merged.csv')\n",
        "Fur_merged_final = pd.read_csv('furnace_cylce_merged_final.csv')"
      ],
      "metadata": {
        "id": "buZv1L5EZEQ_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Fur_merged=Fur_merged.dropna()\n",
        "Fur_merged_final=Fur_merged_final.dropna()"
      ],
      "metadata": {
        "id": "uGZCt3vBjNLX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split data into training and test data.\n",
        "x1 = Big_data_imputed[['Current_Roof_Temp']].values\n",
        "y1 = Big_data_imputed[['Metal_Temp']].values\n",
        "#split data into training and test data.\n",
        "x2 = Fur_merged[['Mins', 'Current_Roof_Temp']].values\n",
        "y2 = Fur_merged[['Metal_Temp']].values\n",
        "#split data into training and test data.\n",
        "x3 = Fur_merged_final[['Mins', 'Current_Roof_Temp', 'roof_temperature_1','roof_temperature_2']].values\n",
        "y3 = Fur_merged_final[['Metal_Temp']].values"
      ],
      "metadata": {
        "id": "U3fE_soDZ4wT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x1_train, x1_test, y1_train, y1_test = train_test_split(x1,y1, test_size = 0.3, random_state = 65)\n",
        "x2_train, x2_test, y2_train, y2_test = train_test_split(x2,y2, test_size = 0.3, random_state = 66)\n",
        "x3_train, x3_test, y3_train, y3_test = train_test_split(x3,y3, test_size = 0.3, random_state = 67)"
      ],
      "metadata": {
        "id": "GLEKiXR5apsf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANN Model"
      ],
      "metadata": {
        "id": "FNJRTkHFb6DC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import deeplearning libraries\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        " \n",
        "# create ANN model\n",
        "model_ann = Sequential()\n",
        " \n",
        "# Defining the Input layer and FIRST hidden layer, both are same!\n",
        "model_ann.add(Dense(units=20, input_dim=1, kernel_initializer='normal', activation='relu'))\n",
        " \n",
        "# Defining the Second layer of the model\n",
        "# after the first layer we don't have to specify input_dim as keras configure it automatically\n",
        "model_ann.add(Dense(units=20, kernel_initializer='normal', activation='tanh'))\n",
        " \n",
        "# The output neuron is a single fully connected node \n",
        "# Since we will be predicting a single number\n",
        "model_ann.add(Dense(1, kernel_initializer='normal'))\n",
        " \n",
        "# Compiling the model\n",
        "model_ann.compile(loss='mean_squared_error', optimizer='adam')\n",
        " \n",
        "# Fitting the ANN to the Training set\n",
        "model_ann.fit(x1_train, y1_train ,batch_size = 20, epochs = 25, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCCEaz9Abvz1",
        "outputId": "23d5b323-00a0-4660-f3e5-94b84797eb52"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "7584/7584 [==============================] - 12s 2ms/step - loss: 400657.8125\n",
            "Epoch 2/25\n",
            "7584/7584 [==============================] - 12s 2ms/step - loss: 234939.0312\n",
            "Epoch 3/25\n",
            "7584/7584 [==============================] - 12s 2ms/step - loss: 117669.1953\n",
            "Epoch 4/25\n",
            "7584/7584 [==============================] - 12s 2ms/step - loss: 47350.6523\n",
            "Epoch 5/25\n",
            "7584/7584 [==============================] - 12s 2ms/step - loss: 19927.7109\n",
            "Epoch 6/25\n",
            "7584/7584 [==============================] - 13s 2ms/step - loss: 17058.0020\n",
            "Epoch 7/25\n",
            "7584/7584 [==============================] - 14s 2ms/step - loss: 17049.4297\n",
            "Epoch 8/25\n",
            "7584/7584 [==============================] - 11s 1ms/step - loss: 17048.4336\n",
            "Epoch 9/25\n",
            "7584/7584 [==============================] - 11s 2ms/step - loss: 17045.9004\n",
            "Epoch 10/25\n",
            "7584/7584 [==============================] - 11s 1ms/step - loss: 17045.2051\n",
            "Epoch 11/25\n",
            "7584/7584 [==============================] - 11s 1ms/step - loss: 17046.8730\n",
            "Epoch 12/25\n",
            "7584/7584 [==============================] - 11s 2ms/step - loss: 17044.2383\n",
            "Epoch 13/25\n",
            "7584/7584 [==============================] - 12s 2ms/step - loss: 17044.4316\n",
            "Epoch 14/25\n",
            "7584/7584 [==============================] - 11s 1ms/step - loss: 17043.7754\n",
            "Epoch 15/25\n",
            "7584/7584 [==============================] - 11s 2ms/step - loss: 17043.2207\n",
            "Epoch 16/25\n",
            "7584/7584 [==============================] - 11s 1ms/step - loss: 17042.7305\n",
            "Epoch 17/25\n",
            "7584/7584 [==============================] - 11s 2ms/step - loss: 17041.9512\n",
            "Epoch 18/25\n",
            "7584/7584 [==============================] - 12s 2ms/step - loss: 17040.3984\n",
            "Epoch 19/25\n",
            "7584/7584 [==============================] - 11s 2ms/step - loss: 17041.5117\n",
            "Epoch 20/25\n",
            "7584/7584 [==============================] - 11s 2ms/step - loss: 17042.5664\n",
            "Epoch 21/25\n",
            "7584/7584 [==============================] - 11s 2ms/step - loss: 17041.5820\n",
            "Epoch 22/25\n",
            "7584/7584 [==============================] - 12s 2ms/step - loss: 17041.4297\n",
            "Epoch 23/25\n",
            "7584/7584 [==============================] - 12s 2ms/step - loss: 17041.0547\n",
            "Epoch 24/25\n",
            "7584/7584 [==============================] - 12s 2ms/step - loss: 17039.3047\n",
            "Epoch 25/25\n",
            "7584/7584 [==============================] - 11s 2ms/step - loss: 17040.9551\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3d029b61d0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import deeplearning libraries\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        " \n",
        "# create ANN model\n",
        "model_ann1 = Sequential()\n",
        " \n",
        "# Defining the Input layer and FIRST hidden layer, both are same!\n",
        "model_ann1.add(Dense(units=20, input_dim=2, kernel_initializer='normal', activation='relu'))\n",
        " \n",
        "# Defining the Second layer of the model\n",
        "# after the first layer we don't have to specify input_dim as keras configure it automatically\n",
        "model_ann1.add(Dense(units=20, kernel_initializer='normal', activation='tanh'))\n",
        " \n",
        "# The output neuron is a single fully connected node \n",
        "# Since we will be predicting a single number\n",
        "model_ann1.add(Dense(1, kernel_initializer='normal'))\n",
        " \n",
        "# Compiling the model\n",
        "model_ann1.compile(loss='mean_squared_error', optimizer='adam')\n",
        " \n",
        "# Fitting the ANN to the Training set\n",
        "\n",
        "model_ann1.fit(x2_train, y2_train ,batch_size = 20, epochs = 25, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlD2fPQ5h0N4",
        "outputId": "b097ebf1-717b-4663-92de-cd0f565d74a4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 479225.1250\n",
            "Epoch 2/25\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 477628.5000\n",
            "Epoch 3/25\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 476105.3125\n",
            "Epoch 4/25\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 474592.2188\n",
            "Epoch 5/25\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 473086.6875\n",
            "Epoch 6/25\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 471583.4375\n",
            "Epoch 7/25\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 470084.7188\n",
            "Epoch 8/25\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 468591.5625\n",
            "Epoch 9/25\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 467099.1875\n",
            "Epoch 10/25\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 465615.9688\n",
            "Epoch 11/25\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 464141.7188\n",
            "Epoch 12/25\n",
            "54/54 [==============================] - 0s 1ms/step - loss: 462665.7188\n",
            "Epoch 13/25\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 461195.7500\n",
            "Epoch 14/25\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 459728.7812\n",
            "Epoch 15/25\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 458266.7500\n",
            "Epoch 16/25\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 456806.7812\n",
            "Epoch 17/25\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 455350.5000\n",
            "Epoch 18/25\n",
            "54/54 [==============================] - 0s 1ms/step - loss: 453897.6562\n",
            "Epoch 19/25\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 452448.1875\n",
            "Epoch 20/25\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 451004.8438\n",
            "Epoch 21/25\n",
            "54/54 [==============================] - 0s 1ms/step - loss: 449562.4062\n",
            "Epoch 22/25\n",
            "54/54 [==============================] - 0s 1ms/step - loss: 448121.4688\n",
            "Epoch 23/25\n",
            "54/54 [==============================] - 0s 1ms/step - loss: 446685.6250\n",
            "Epoch 24/25\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 445253.1250\n",
            "Epoch 25/25\n",
            "54/54 [==============================] - 0s 1ms/step - loss: 443822.3750\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3d028cf750>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import deeplearning libraries\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        " \n",
        "# create ANN model\n",
        "model_ann2 = Sequential()\n",
        " \n",
        "# Defining the Input layer and FIRST hidden layer, both are same!\n",
        "model_ann2.add(Dense(units=20, input_dim=4, kernel_initializer='normal', activation='relu'))\n",
        " \n",
        "# Defining the Second layer of the model\n",
        "# after the first layer we don't have to specify input_dim as keras configure it automatically\n",
        "model_ann2.add(Dense(units=20, kernel_initializer='normal', activation='tanh'))\n",
        " \n",
        "# The output neuron is a single fully connected node \n",
        "# Since we will be predicting a single number\n",
        "model_ann2.add(Dense(1, kernel_initializer='normal'))\n",
        " \n",
        "# Compiling the model\n",
        "model_ann2.compile(loss='mean_squared_error', optimizer='adam')\n",
        " \n",
        "# Fitting the ANN to the Training set\n",
        "model_ann2.fit(x3_train, y3_train ,batch_size = 20, epochs = 25, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbfmJurrh0Sa",
        "outputId": "cf5d0be6-9c23-4d57-f54a-e2ee655ce76c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "52/52 [==============================] - 1s 1ms/step - loss: 493843.4062\n",
            "Epoch 2/25\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 492324.3125\n",
            "Epoch 3/25\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 490836.5000\n",
            "Epoch 4/25\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 489353.5938\n",
            "Epoch 5/25\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 487872.4688\n",
            "Epoch 6/25\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 486398.3750\n",
            "Epoch 7/25\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 484926.6875\n",
            "Epoch 8/25\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 483461.5938\n",
            "Epoch 9/25\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 481997.8750\n",
            "Epoch 10/25\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 480539.5000\n",
            "Epoch 11/25\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 479080.8750\n",
            "Epoch 12/25\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 477630.1562\n",
            "Epoch 13/25\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 476179.7812\n",
            "Epoch 14/25\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 474733.7812\n",
            "Epoch 15/25\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 473289.4375\n",
            "Epoch 16/25\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 471849.9062\n",
            "Epoch 17/25\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 470413.4688\n",
            "Epoch 18/25\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 468981.2500\n",
            "Epoch 19/25\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 467551.4062\n",
            "Epoch 20/25\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 466125.0625\n",
            "Epoch 21/25\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 464700.5000\n",
            "Epoch 22/25\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 463282.5938\n",
            "Epoch 23/25\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 461863.9375\n",
            "Epoch 24/25\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 460452.8125\n",
            "Epoch 25/25\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 459040.5938\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3d027d8d10>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest Regressor"
      ],
      "metadata": {
        "id": "G8XUsjtccaFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "model_rf = RandomForestRegressor(n_estimators=100, oob_score=True, random_state=100)\n",
        "model_rf1 = RandomForestRegressor(n_estimators=100, oob_score=True, random_state=100)\n",
        "model_rf2 = RandomForestRegressor(n_estimators=100, oob_score=True, random_state=100)\n",
        "model_rf.fit(x1_train, y1_train)\n",
        "model_rf1.fit(x2_train, y2_train) \n",
        "model_rf2.fit(x3_train, y3_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b2mO5xAcZIJ",
        "outputId": "95a0a65e-3f9e-4fb4-fd36-bb8ecc1d204b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  import sys\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(oob_score=True, random_state=100)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM Regressor"
      ],
      "metadata": {
        "id": "mkg3RmNLknbB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM Regression\n",
        "#from sklearn import svm\n",
        "#RegModel = svm.SVR(C=2, kernel='linear')\n",
        "#RegModel1 = svm.SVR(C=2, kernel='linear')\n",
        "#RegModel2 = svm.SVR(C=2, kernel='linear')\n",
        "#Creating the model on Training Data\n",
        "#RegModel.fit(x1_train,y1_train)\n",
        "#RegModel1.fit(x2_train,y2_train)\n",
        "#RegModel2.fit(x3_train,y3_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiFYFLinktys",
        "outputId": "650b928e-4d44-4c55-8024-68d9e2588a26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gaussian Process"
      ],
      "metadata": {
        "id": "UHSAZ5olmHza"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#GP\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "kernel = 1 * RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e2))\n",
        "gaussian_process = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9)\n",
        "gaussian_process1 = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9)\n",
        "gaussian_process2 = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9)\n",
        "gaussian_process.fit(x1_train, y1_train)\n",
        "gaussian_process1.fit(x2_train, y2_train)\n",
        "gaussian_process2.fit(x3_train, y3_train)\n",
        "gaussian_process.kernel_\n",
        "gaussian_process1.kernel_\n",
        "gaussian_process2.kernel_"
      ],
      "metadata": {
        "id": "UGMGlP3zmLu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction"
      ],
      "metadata": {
        "id": "NgKRTqBDdKmL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ann Prediction\n",
        "y1_pred_train_ann= model_ann.predict(y1_test)\n",
        "y2_pred_train_ann= model_ann1.predict(y2_test)\n",
        "y3_pred_train_ann= model_ann2.predict(y3_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 835
        },
        "id": "yfCc0QHFdJDy",
        "outputId": "ca22fadb-a6c5-4e9f-f5cb-c1c6cab355e4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 2) for input KerasTensor(type_spec=TensorSpec(shape=(None, 2), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 1).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-fcc1931fcd4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Ann Prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my1_pred_train_ann\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel_ann\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0my2_pred_train_ann\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel_ann1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my2_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0my3_pred_train_ann\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel_ann2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my3_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 249, in assert_input_compatibility\n        f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Exception encountered when calling layer \"sequential_1\" (type Sequential).\n    \n    Input 0 of layer \"dense_3\" is incompatible with the layer: expected axis -1 of input shape to have value 2, but received input with shape (None, 1)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None, 1), dtype=float32)\n      • training=False\n      • mask=None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Random forest Prediction\n",
        "y1_pred_train_rf= model_rf.predict(y1_test)\n",
        "y2_pred_train_rf= model_rf1.predict(y2_test)\n",
        "y3_pred_train_rf= model_rf2.predict(y3_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "OhYiHuGcrIQj",
        "outputId": "d6102139-f919-4792-b77c-d44bfa1ca445"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-efe6c687a368>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Random forest Prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my1_pred_train_rf\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel_rf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0my2_pred_train_rf\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel_rf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my2_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0my3_pred_train_rf\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel_rf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my3_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    969\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 971\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    577\u001b[0m         Validate X whenever one tries to predict, apply, predict_proba.\"\"\"\n\u001b[1;32m    578\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No support for np.int64 index based sparse matrices\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             raise ValueError(\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: X has 1 features, but RandomForestRegressor is expecting 2 features as input."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM PRediction\n",
        "prediction=SVM.predict(x1_test)\n",
        "prediction=SVM.predict(x2_test)\n",
        "prediction=SVM.predict(x3_test)\n",
        "pred_train_rf= model_rf.predict(x_train)\n",
        "\n",
        "\n",
        "pred_test_rf = model_rf.predict(x_test)\n",
        "print(np.sqrt(mean_squared_error(y_test,pred_test_rf)))\n",
        "print(r2_score(y_test, pred_test_rf))"
      ],
      "metadata": {
        "id": "SULbCqrPrUuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "#print(np.sqrt(mean_squared_error(y1_test,y1_pred_train_ann)))\n",
        "#print(np.sqrt(mean_squared_error(y2_test,y2_pred_train_ann)))\n",
        "#print(np.sqrt(mean_squared_error(y3_test,y3_pred_train_ann)))\n",
        "#print(r2_score(y1_test,y1_pred_train_rf))\n",
        "print(r2_score(y2_test,y2_pred_train_rf))\n",
        "print(r2_score(y3_test,y3_pred_train_rf))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "a2Ax2SZnrdqp",
        "outputId": "5d28f69d-a504-4f7b-bd24-08b2a3027530"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-45295cc1ee42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#print(np.sqrt(mean_squared_error(y3_test,y3_pred_train_ann)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#print(r2_score(y1_test,y1_pred_train_rf))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my2_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my2_pred_train_rf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my3_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my3_pred_train_rf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36mr2_score\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    788\u001b[0m     \"\"\"\n\u001b[1;32m    789\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0;32m--> 790\u001b[0;31m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultioutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m     )\n\u001b[1;32m    792\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mthe\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0margument\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mto\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \"\"\"\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    332\u001b[0m         raise ValueError(\n\u001b[1;32m    333\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         )\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [457, 1065]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.sqrt(mean_squared_error(y_train,pred_train_rf)))\n",
        "print(r2_score(y_train, pred_train_rf))"
      ],
      "metadata": {
        "id": "w7A6J2uWsCM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_prediction, std_prediction = gaussian_process.predict(x1, return_std=True)\n",
        "plt.plot(x1, y1, label=r\"$f(x) = x \\sin(x)$\", linestyle=\"dotted\")\n",
        "plt.scatter(x_train, y_train, label=\"Observations\")\n",
        "plt.plot(x1, mean_prediction, label=\"Mean prediction\")\n",
        "plt.fill_between(\n",
        "    x.ravel(),\n",
        "    mean_prediction - 1.96 * std_prediction,\n",
        "    mean_prediction + 1.96 * std_prediction,\n",
        "    alpha=0.5,\n",
        "    label=r\"95% confidence interval\",\n",
        ")\n",
        "plt.legend()\n",
        "plt.xlabel(\"$x$\")\n",
        "plt.ylabel(\"$f(x)$\")\n",
        "_ = plt.title(\"Gaussian process regression on noise-free dataset\")"
      ],
      "metadata": {
        "id": "AbD9vB3Imf0P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}